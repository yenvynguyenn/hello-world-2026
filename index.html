<html> 
  <head>
    <title>Hello CWD Index</title>
  </head>
  <body>
    <h1>My First Webpage!</h1>
    <p>Hello, world! This is my webpage! I hope you like it!</p>
    <h2>Selections from the CWD Index</h2>
    <p><a href="https://www.nytimes.com/interactive/2023/12/22/technology/openai-chatgpt-privacy-exploit.html"> How Strangers Got My Email Address From Chat GPT's Model</a><br>
    My name is Owen Mundy (he/him). I live in Davidson, North Carolina, and I usually describe myself as someone deeply interested in how digital tools shape our everyday lives. That’s why I’ve been paying attention to how AI systems handle personal data — especially when they promise convenience and insight. One of the articles that really made me think was The New York Times’ piece about a potential privacy flaw in OpenAI’s ChatGPT, where researchers showed that sensitive information could be extracted from the AI under certain conditions, raising serious questions about what data these large models might retain or reveal. It reminded me how crucial it is to balance innovation with respect for privacy, because tools like ChatGPT are everywhere and we often trust them with our thoughts and information without fully understanding the risks..</p>
      <p><a href="https://pudding.cool/2021/10/lenna/"> Can Data Die</a><br>
    The Lenna image began as a 1972 Playboy photograph of Swedish model Lena Forsén that engineers at the University of Southern California scanned into digital form for early image processing research. Over decades it became a widely used test image in computer vision, appearing in classrooms, research papers, and software around the world. In recent years, critics and Forsén herself have called for the image to be retired because it continues to be used without her consent and its source can shape perceptions of women in tech.</p>
